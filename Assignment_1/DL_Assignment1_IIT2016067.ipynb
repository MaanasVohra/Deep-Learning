{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_Assignment1_IIT2016067","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"pFWnfYwBdIea","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3umjw26bdWep","colab_type":"code","colab":{}},"source":["# generating images with one channel of pixel values in range 0-255\n","# params :\n","# (1) image_height : height of image\n","# (2) image_width  : width of image\n","# (3) batch_size   : number of images in the batch sample\n","\n","def generate_batch_images(image_height=28, \n","                          image_width=28, \n","                          batch_size=50) :\n","  \n","  batch_images = np.zeros((batch_size, image_height, image_width))\n","  \n","  for i in range(batch_size) :\n","    batch_images[i] = np.random.randint(0, \n","                                        high=256, \n","                                        size=(image_height, image_width))\n","  \n","  return batch_images"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mxrXkqqImYXJ","colab":{}},"source":["# applying zero padding to the image\n","# params : \n","# (1) image : numpy array image of one channel\n","# (2) padding_size_arr : tuple of tuples containing \n","#                        the description for padding\n","\n","def apply_zero_padding_image(image, padding_size_arr) :\n","  assert(len(padding_size_arr) == len(image.shape))\n","  image = np.pad(image, padding_size_arr, 'constant')\n","  \n","  return image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"45J6kj6ou5oB","colab_type":"code","colab":{}},"source":["# apply zero padding to batch of images\n","# params : \n","# (1) batch : batch of numpy images of one channel\n","# (2) padding_size_arr : tuple of tuples containing \n","#                        the description for padding\n","\n","def apply_zero_padding_batch(batch, padding_size_arr) :\n","  \n","  assert(len(padding_size_arr) == len(batch.shape) - 1)\n","    \n","  new_size = [batch.shape[0]]\n","  for i in range(0, len(padding_size_arr)) :\n","    new_size.append(batch.shape[i + 1] + 2 * padding_size_arr[i][0])\n","  new_size = tuple(new_size)\n","    \n","  new_batch = np.zeros(new_size)\n","  \n","  for i in range(batch.shape[0]) :\n","    new_batch[i] = apply_zero_padding_image(batch[i], padding_size_arr)\n","    \n","  return new_batch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"soZDJqBZuEWD","colab_type":"code","outputId":"1945acc2-ee44-4a63-a5bf-76406284e3b2","executionInfo":{"status":"ok","timestamp":1567490381441,"user_tz":-330,"elapsed":1678,"user":{"displayName":"Maanas Vohra","photoUrl":"","userId":"05576219587563581628"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#(Q1) applying padding\n","\n","padding_size_arr = ((1, 1), (2, 2))\n","batch = generate_batch_images()\n","print(\"old shape => \", batch.shape)\n","new_batch = apply_zero_padding_batch(batch, padding_size_arr)\n","print(\"new shape => \", new_batch.shape)"],"execution_count":158,"outputs":[{"output_type":"stream","text":["old shape =>  (50, 28, 28)\n","new shape =>  (50, 30, 32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IY-6kf7mzgNY","colab_type":"code","colab":{}},"source":["# convolution at one position, here applied at beginning\n","# params :\n","# (1) image: numpy array image in one channel\n","# (2) convolution filter(usually of size 3 X 3)\n","\n","def convolve_at_beginning(image, convolve_filter) :\n","  \n","  assert(convolve_filter.shape[0] <= image.shape[0]\n","     and convolve_filter.shape[1] <= image.shape[1])\n","  \n","  result = 0\n","  \n","  for i in range(convolve_filter.shape[0]) :\n","    for j in range(convolve_filter.shape[1]) :\n","      result += convolve_filter[i][j] * image[i][j]\n","      \n","  return result"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YP2yHAGc1SGs","colab_type":"code","outputId":"78b70718-06c4-4af7-da22-d79df11707be","executionInfo":{"status":"ok","timestamp":1567490381442,"user_tz":-330,"elapsed":1659,"user":{"displayName":"Maanas Vohra","photoUrl":"","userId":"05576219587563581628"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#(Q2) applying convolution operation at beginning\n","\n","image = batch[0]\n","convolve_filter = np.array([[1, 1, 1], [0, 0, 0], [0, 0, 0]])\n","\n","convolution_result = convolve_at_beginning(image, convolve_filter)\n","print(\"result of convolution is => \", convolution_result)"],"execution_count":160,"outputs":[{"output_type":"stream","text":["result of convolution is =>  412.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I3pBh7iX1WLM","colab_type":"code","colab":{}},"source":["convolve_filters = np.array([\n","    [[1, 1, 1],\n","    [0, 0, 0],\n","    [0, 0, 0]],\n","    \n","    [[0, 0, 0],\n","    [1, 1, 1],\n","    [0, 0, 0]],\n","    \n","    [[0, 0, 0],\n","    [0, 0, 0],\n","    [1, 1, 1]],\n","    \n","    [[1, 1, 1],\n","    [0, 0, 0],\n","    [-1, -1, -1]],\n","    \n","    [[1, 0, -1],\n","    [1, 0, -1],\n","    [1, 0, -1]]\n","])\n","\n","bias_convolve_filters = np.array([5, 4, 3, 2, 1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MNRJJ1opIrmq","colab_type":"code","colab":{}},"source":["def activation_function_relu(image) :\n","  return np.maximum(image, 0)\n","\n","def activation_function_leaky_relu(image) :\n","  return np.maximum(image, 0.01 * image)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NiMnEy1711Pt","colab_type":"code","colab":{}},"source":["# convolution for a list of filters, in this example\n","# I implemented using 3X3 simple filters\n","# params\n","\n","# (1) A_prev : Activation from previous layer\n","# (2) convolve_filters : List of filters used for convolution\n","# (3) Stride : Stride used for convolution operation\n","\n","def convolve_image_with_filters(A_prev, convolve_filters, bias_convolve_filters, stride=1) :\n","  \n","  filter_count = convolve_filters.shape[0]\n","  convolve_result_height = int(np.floor((A_prev.shape[0] - convolve_filters.shape[1])/stride + 1))\n","  convolve_result_width  = int(np.floor((A_prev.shape[1] - convolve_filters.shape[2])/stride + 1))\n","  \n","  convolve_result = np.zeros((filter_count, convolve_result_height, convolve_result_width))\n","  \n","  for i in range(convolve_result.shape[0]) :\n","    for j in range(convolve_result.shape[1]) :\n","      for k in range(convolve_result.shape[2]) :\n","        \n","        horiz_start = j * stride\n","        horiz_end = horiz_start + convolve_filters[i].shape[0]\n","        \n","        vert_start = k * stride\n","        vert_end = vert_start + convolve_filters[i].shape[1]\n","        \n","        image_section = A_prev[horiz_start : horiz_end, vert_start : vert_end]\n","        \n","        convolve_result[i][j][k] = np.sum(np.multiply(image_section, convolve_filters[i]))\n","    \n","    convolve_result[i] = convolve_result[i] + bias_convolve_filters[i]\n","    \n","    # apply activation function relu\n","    # convolve_result[i] = activation_function_relu(convolve_result[i])\n","    \n","  return convolve_result"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Ha5Zdhg2AJt","colab_type":"code","outputId":"7d9c7824-28b1-44a0-c055-44f4f6eeb353","executionInfo":{"status":"ok","timestamp":1567490381445,"user_tz":-330,"elapsed":1632,"user":{"displayName":"Maanas Vohra","photoUrl":"","userId":"05576219587563581628"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Applying convolution on image of one channel\n","\n","convolution_result_1 = convolve_image_with_filters(image, convolve_filters, bias_convolve_filters, stride=2)\n","print(\"shape of convolution result => \", convolution_result_1.shape)"],"execution_count":164,"outputs":[{"output_type":"stream","text":["shape of convolution result =>  (5, 13, 13)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jI226yYLKxGp","colab_type":"code","colab":{}},"source":["# average pooling on image of one channel\n","# params :\n","\n","# (1) image : image of one channel on which pooling is applied\n","# (2) filter_size : filter size on which pooling is to be applied\n","# (3) stride : stride used for pooling operation\n","\n","def average_pooling(image, filter_size, stride=1) :\n","  \n","  pool_result_height = int(np.floor((image.shape[0] - filter_size[0])/stride + 1))\n","  pool_result_width = int(np.floor((image.shape[1] - filter_size[1])/stride + 1))\n","  \n","  pool_result = np.zeros((pool_result_height, pool_result_width))\n","      \n","  for i in range(pool_result.shape[0]) :\n","    for j in range(pool_result.shape[1]) :\n","      \n","      horiz_start = i * stride\n","      horiz_end = horiz_start + filter_size[0]\n","      \n","      vert_start = j * stride\n","      vert_end = vert_start + filter_size[1]\n","      \n","      image_section = image[horiz_start : horiz_end, vert_start : vert_end]\n","      \n","      pool_result[i][j] = float(np.sum(image_section)/float(filter_size[0] * filter_size[1]))\n","      \n","  return pool_result"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dfh_sm-wP1VR","colab_type":"code","colab":{}},"source":["# max pooling on image of one channel\n","# params :\n","\n","# (1) image : image of one channel on which pooling is applied\n","# (2) filter_size : filter size on which pooling is to be applied\n","# (3) stride : stride used for pooling operation\n","\n","def max_pooling(image, filter_size, stride=1) :\n","  \n","  pool_result_height = int(np.floor((image.shape[0] - filter_size[0])/stride + 1))\n","  pool_result_width = int(np.floor((image.shape[1] - filter_size[1])/stride + 1))\n","  \n","  pool_result = np.zeros((pool_result_height, pool_result_width))\n","  \n","  for i in range(pool_result.shape[0]) :\n","    for j in range(pool_result.shape[1]) :\n","      \n","      horiz_start = i * stride\n","      horiz_end = horiz_start + filter_size[0]\n","      \n","      vert_start = j * stride\n","      vert_end = vert_start + filter_size[1]\n","      \n","      image_section = image[horiz_start : horiz_end, vert_start : vert_end]\n","      \n","      pool_result[i][j] = np.amax(image_section)\n","      \n","  return pool_result\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YKP21t6FQwm8","colab_type":"code","colab":{}},"source":["# applying average pooling \n","\n","filter_size = np.array([3, 3])\n","average_pool_result = average_pooling(image, filter_size, stride=2)\n","\n","# applying max pooling\n","\n","max_pooling_result = max_pooling(image, filter_size, stride=2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QsySwcyDYrMg","colab_type":"text"},"source":["In CNN, the features are extracted by using the values present in the filter used for convolution and the bias corresponding to each filter. When we apply the convolution operation to the image and then use some activation function(like ReLU), we get some output. This output is propogated forward to many layers and in the end we apply backpropogation to adjust the values present in the CNN filter and bias.\n","\n","The backpropogation algorithm is similar to that applied in DNN and we can use gradient descent to optimise the weights and bias terms.\n"]},{"cell_type":"markdown","metadata":{"id":"iqBycgIUZfx9","colab_type":"text"},"source":[""]}]}